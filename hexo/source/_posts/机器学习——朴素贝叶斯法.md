---
title: 朴素贝叶斯法
top: false
cover: false
toc: true
mathjax: true
date: 2019-09-21 19:28:49
password:
summary:
copyright: true
tags: 
  - ML
  - 朴素贝叶斯
  - 概率
categories:
  - Machine learning
---

### 概率和统计

概率和统计是两个相近的概率，研究的内容不同：

- 概率：已知一个模型和参数，怎么去预测这个模型产生的结果的特性（例如均值，方差，协方差等）

- 统计：有已知的数据，要利用这堆数据去反推出合适的模型和参数

**概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。**



> 贝叶斯理论是统计学中一个非常重要的也是出名的理论。贝叶斯学派强调的是概率的“主观性”。
>
> - 频率学派强调频率的“自然属性”，认为应该使用事件在重复试验中发生的频率作为事件发生的概率估计
>
> - 贝叶斯学派认为事件是具有随机性的，随机性的 根源在于不同的人对事件的认知状态不同。

栗子：一个人掷硬币，迅速将硬币捂住，他本人是知道正面朝上，由近及远的3个人看到了模糊的信息，坐的越远，信息越少。

- 频率派：该硬币出现正、反的概率各是`50%`
- 贝叶斯派：掷硬币的人知道正面朝上的概率是`100%`，对离他最近的人来说是`80%`，最远的人是`50%`



<!-- MORE-->

### 贝叶斯决策论

- 行动空间$A$：实际工作中可能采取的各种行动所构成的集合。

- 决策$\delta(x)$：样本空间`X`到行动空间`A`的一个映射

- 损失函数：$L(\theta,a)=L(\theta,\delta(\hat X))$，表示的是参数是$\theta$时采取行动$a$所造成的损失

- 决策风险：$R(\theta, \delta)$，它是损失函数的期望
  $$
  R(\theta,\delta)=EL(\theta,\delta(\hat X))
  $$
  
- 先验分布：描述的是参数$\theta$在已知样本$\hat X$中的分布

- 平均风险：决策风险在先验分布下的期望
  $$
  \rho(\delta)=E_\varepsilon R(\theta, \delta)
  $$
  
- 贝叶斯决策满足：
  $$
  \rho(\delta^*)=\inf_\delta \rho(\delta)
  $$
  



### 贝叶斯公式

条件几率的公式
$$
P(B|A)=\frac {P(B\cap A)}{P(A)}
$$
解释为：`A发生的前提下，B发生的概率 = AB交集发生的概率 / A发生的概率`  ，另写作：
$$
{P(B\cap A)}= P(B|A){P(A)}
$$


![](https://s2.ax1x.com/2019/09/21/nzgGyd.png)



看下贝叶斯公式：
$$
P(A|B)=\frac {P(B|A)P(A)} {P(B)}
$$




### 极大似然估计(MLE)

> 极大似然估计`Maximum likelihood estimation`就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值，属于统计问题。提供了一种给定观察数据来评估模型参数的方法，即：**“模型已定，参数未知”**

[一文搞懂极大似然估计](https://zhuanlan.zhihu.com/p/26614750)

[详解最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式的理解](https://blog.csdn.net/u011508640/article/details/72815981)



----

似然函数能够输出$\hat X=(x_1,...,x_N)^T$，当参数是$\theta$时候，输入为$\hat X$的概率，似然函数$p(\hat X|\theta)$满足：
$$
p(\hat X|\theta)=\prod_{i=1}^N p(x_i|\theta)
$$


希望找到$\hat \theta$满足
$$
\hat \theta= \mathop {arg max}\limits_{\theta}p(\hat X|\theta)=\mathop {arg max}\limits_{\theta}{\prod_{i=1}^N p(x_i|\theta)}
$$


